{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "47d14c1eef8943c39c4c039ad9ab44ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ae7343977f2a4bc39b4517c18db8ac96",
              "IPY_MODEL_caaa1620eb6a4a12ace08d5d870bc020",
              "IPY_MODEL_ad4498bf17114480830e25cefeaa13e5"
            ],
            "layout": "IPY_MODEL_c46b99046a1142fd951b91ac5e287acf"
          }
        },
        "ae7343977f2a4bc39b4517c18db8ac96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d804f08207a0404298d2adb98589c0ad",
            "placeholder": "​",
            "style": "IPY_MODEL_5941f57b02304f86af14fa66a5791825",
            "value": ""
          }
        },
        "caaa1620eb6a4a12ace08d5d870bc020": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d86ddd4346f4ba1902cd632df247c13",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_39c14aa6bac6466498fadc87d85cadf6",
            "value": 1
          }
        },
        "ad4498bf17114480830e25cefeaa13e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_195786f5233345298181e6dcc3a6de02",
            "placeholder": "​",
            "style": "IPY_MODEL_3e10cc7a3f1f4fdd9d38f5584e384630",
            "value": " 7420/? [00:47&lt;00:00, 158.94it/s]"
          }
        },
        "c46b99046a1142fd951b91ac5e287acf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d804f08207a0404298d2adb98589c0ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5941f57b02304f86af14fa66a5791825": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d86ddd4346f4ba1902cd632df247c13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "39c14aa6bac6466498fadc87d85cadf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "195786f5233345298181e6dcc3a6de02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e10cc7a3f1f4fdd9d38f5584e384630": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aNWItwlVXDE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b091592-8b5b-4c0e-fd66-9fa350d4841f"
      },
      "source": [
        "# Initialization\n",
        "####################################\n",
        "!pip install transformers\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "import tensorflow as tf\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')\n",
        "\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m92.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n",
            "Found GPU at: /device:GPU:0\n",
            "Mon May  1 04:52:15 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    51W / 400W |    691MiB / 40960MiB |      1%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configs\n",
        "####################################\n",
        "\n",
        "### Dataset config\n",
        "\n",
        "# hackerone-report-20types-weakness.csv\n",
        "# hackerone-report-20types-bounty_range.csv\n",
        "# hackerone-report-20types-severity.csv\n",
        "\n",
        "# weakness clasification\n",
        "# classes = ['CWE-77', 'CWE-22', 'CWE-310', 'CWE-89', 'CWE-918', 'CWE-639', 'CWE-103', 'CWE-400', 'CWE-287', 'CWE-657', 'CWE-79', 'CWE-284', 'CWE-352', 'CWE-200', 'CWE-840', 'CWE-233', 'CWE-94', 'CWE-601', 'CWE-119', 'other'];\n",
        "# datasetUrl = 'https://raw.githubusercontent.com/SamanShafigh/vulBERT/main/hackerone-report-20types-weakness.csv';\n",
        "\n",
        "# # bounty_range clasification\n",
        "classes = ['undefined', 'low', 'medium', 'high', 'extreme'];\n",
        "datasetUrl = 'https://raw.githubusercontent.com/SamanShafigh/vulBERT/main/hackerone-report-20types-bounty_range.csv';\n",
        "\n",
        "# severity clasification\n",
        "# classes = ['undefined', 'low', 'medium', 'high', 'critical'];\n",
        "# datasetUrl = 'https://raw.githubusercontent.com/SamanShafigh/vulBERT/main/hackerone-report-20types-severity.csv';\n",
        "\n",
        "\n",
        "### Training config\n",
        "epochs = 20\n"
      ],
      "metadata": {
        "id": "UbJbpp_TKSRX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5KlWWtynZib"
      },
      "source": [
        "### **Data Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeyCO71yZxYY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263,
          "referenced_widgets": [
            "47d14c1eef8943c39c4c039ad9ab44ef",
            "ae7343977f2a4bc39b4517c18db8ac96",
            "caaa1620eb6a4a12ace08d5d870bc020",
            "ad4498bf17114480830e25cefeaa13e5",
            "c46b99046a1142fd951b91ac5e287acf",
            "d804f08207a0404298d2adb98589c0ad",
            "5941f57b02304f86af14fa66a5791825",
            "8d86ddd4346f4ba1902cd632df247c13",
            "39c14aa6bac6466498fadc87d85cadf6",
            "195786f5233345298181e6dcc3a6de02",
            "3e10cc7a3f1f4fdd9d38f5584e384630"
          ]
        },
        "outputId": "6ddefd3e-de1d-4b49-cb5e-6a093d3caca8"
      },
      "source": [
        "# Load dataset\n",
        "####################################\n",
        "\n",
        "df = pd.read_csv(datasetUrl, sep='\\t')\n",
        "numberOfClasses = len(classes)\n",
        "print(numberOfClasses)\n",
        "\n",
        "df.head()\n",
        "df.info()\n",
        "df.drop(len(df)-1, inplace=True)\n",
        "df['type'] = df['type'].astype(int)\n",
        "df['type'].value_counts()\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "\n",
        "\n",
        "# Define train & val dataset\n",
        "####################################\n",
        "X_input_ids = np.zeros((len(df), 256))\n",
        "X_attn_masks = np.zeros((len(df), 256))\n",
        "\n",
        "def generate_training_data(df, ids, masks, tokenizer):\n",
        "    for i, text in tqdm(enumerate(df['report'])):\n",
        "        tokenized_text = tokenizer.encode_plus(\n",
        "            text,\n",
        "            max_length=256, \n",
        "            truncation=True, \n",
        "            padding='max_length', \n",
        "            add_special_tokens=True,\n",
        "            return_tensors='tf'\n",
        "        )\n",
        "        ids[i, :] = tokenized_text.input_ids\n",
        "        masks[i, :] = tokenized_text.attention_mask\n",
        "    return ids, masks\n",
        "\n",
        "print(\"generate training data\")\n",
        "X_input_ids, X_attn_masks = generate_training_data(df, X_input_ids, X_attn_masks, tokenizer) \n",
        "labels = np.zeros((len(df), numberOfClasses))\n",
        "labels.shape\n",
        "labels[np.arange(len(df)), df['type'].values] = 1 # one-hot encoded target tensor\n",
        "\n",
        "# creating a data pipeline using tensorflow dataset utility, creates batches of data for easy loading...\n",
        "dataset = tf.data.Dataset.from_tensor_slices((X_input_ids, X_attn_masks, labels))\n",
        "dataset.take(1) # one sample data\n",
        "\n",
        "def SentimentDatasetMapFunction(input_ids, attn_masks, labels):\n",
        "    return {\n",
        "        'input_ids': input_ids,\n",
        "        'attention_mask': attn_masks\n",
        "    }, labels\n",
        "\n",
        "dataset = dataset.map(SentimentDatasetMapFunction) # converting to required format for tensorflow dataset \n",
        "dataset.take(1)\n",
        "\n",
        "dataset = dataset.shuffle(10000).batch(16, drop_remainder=True) # batch size, drop any left out tensor\n",
        "\n",
        "p = 0.8\n",
        "train_size = int((len(df)//16)*p) # for each 16 batch of data we will have len(df)//16 samples, take 80% of that for train.\n",
        "\n",
        "train_dataset = dataset.take(train_size)\n",
        "val_dataset = dataset.skip(train_size)\n",
        "\n",
        "print(\"Train size: \" + str(train_size))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7421 entries, 0 to 7420\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   report  7421 non-null   object\n",
            " 1   type    7421 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 116.1+ KB\n",
            "generate training data\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "47d14c1eef8943c39c4c039ad9ab44ef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 370\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqAvnV3FnSWt"
      },
      "source": [
        "### **Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1PmnsrQjTkr",
        "outputId": "a7e75df6-6063-440e-90c4-63ac0a0264c9"
      },
      "source": [
        "# Setup BERT model\n",
        "####################################\n",
        "from transformers import TFBertModel\n",
        "model = TFBertModel.from_pretrained('bert-base-cased') # bert base model with pretrained weights\n",
        "\n",
        "# defining 2 input layers for input_ids and attn_masks\n",
        "input_ids = tf.keras.layers.Input(shape=(256), name='input_ids', dtype='int32')\n",
        "attn_masks = tf.keras.layers.Input(shape=(256), name='attention_mask', dtype='int32')\n",
        "\n",
        "bert_embds = model.bert(input_ids, attention_mask=attn_masks)[1] # 0 -> activation layer (3D), 1 -> pooled output layer (2D)\n",
        "intermediate_layer = tf.keras.layers.Dense(512, activation='relu', name='intermediate_layer')(bert_embds)\n",
        "output_layer = tf.keras.layers.Dense(numberOfClasses, activation='softmax', name='output_layer')(intermediate_layer) # softmax -> calcs probs of classes\n",
        "\n",
        "sentiment_model = tf.keras.Model(inputs=[input_ids, attn_masks], outputs=output_layer)\n",
        "sentiment_model.summary()\n",
        "\n",
        "optim = tf.keras.optimizers.legacy.Adam(learning_rate=1e-5, decay=1e-6)\n",
        "\n",
        "loss_func = tf.keras.losses.CategoricalCrossentropy()\n",
        "acc = tf.keras.metrics.CategoricalAccuracy('accuracy')\n",
        "\n",
        "sentiment_model.compile(optimizer=optim, loss=loss_func, metrics=[acc])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " bert (TFBertMainLayer)         TFBaseModelOutputWi  108310272   ['input_ids[0][0]',              \n",
            "                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 256,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " intermediate_layer (Dense)     (None, 512)          393728      ['bert[0][1]']                   \n",
            "                                                                                                  \n",
            " output_layer (Dense)           (None, 5)            2565        ['intermediate_layer[0][0]']     \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 108,706,565\n",
            "Trainable params: 108,706,565\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KH1MVgBpmf_s",
        "outputId": "1598b57f-92ab-41bb-fdac-8acaa5104154",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Train model\n",
        "####################################\n",
        "\n",
        "hist = sentiment_model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=20\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "370/370 [==============================] - 49s 104ms/step - loss: 1.1837 - accuracy: 0.5236 - val_loss: 1.1804 - val_accuracy: 0.5296\n",
            "Epoch 2/20\n",
            "370/370 [==============================] - 37s 99ms/step - loss: 1.0986 - accuracy: 0.5492 - val_loss: 0.9706 - val_accuracy: 0.5833\n",
            "Epoch 3/20\n",
            "370/370 [==============================] - 37s 99ms/step - loss: 0.9718 - accuracy: 0.5938 - val_loss: 0.8803 - val_accuracy: 0.6485\n",
            "Epoch 4/20\n",
            "370/370 [==============================] - 37s 99ms/step - loss: 0.8544 - accuracy: 0.6606 - val_loss: 0.6811 - val_accuracy: 0.7480\n",
            "Epoch 5/20\n",
            "370/370 [==============================] - 37s 99ms/step - loss: 0.7521 - accuracy: 0.7164 - val_loss: 0.5551 - val_accuracy: 0.7910\n",
            "Epoch 6/20\n",
            "370/370 [==============================] - 37s 99ms/step - loss: 0.6246 - accuracy: 0.7688 - val_loss: 0.3744 - val_accuracy: 0.8757\n",
            "Epoch 7/20\n",
            "370/370 [==============================] - 37s 99ms/step - loss: 0.5120 - accuracy: 0.8142 - val_loss: 0.3482 - val_accuracy: 0.8871\n",
            "Epoch 8/20\n",
            "370/370 [==============================] - 37s 99ms/step - loss: 0.3985 - accuracy: 0.8613 - val_loss: 0.2277 - val_accuracy: 0.9281\n",
            "Epoch 9/20\n",
            "370/370 [==============================] - 37s 99ms/step - loss: 0.3106 - accuracy: 0.8966 - val_loss: 0.1469 - val_accuracy: 0.9577\n",
            "Epoch 10/20\n",
            "370/370 [==============================] - 37s 99ms/step - loss: 0.2542 - accuracy: 0.9160 - val_loss: 0.0949 - val_accuracy: 0.9778\n",
            "Epoch 11/20\n",
            "370/370 [==============================] - 37s 99ms/step - loss: 0.1983 - accuracy: 0.9353 - val_loss: 0.0883 - val_accuracy: 0.9704\n",
            "Epoch 12/20\n",
            "370/370 [==============================] - 37s 99ms/step - loss: 0.1506 - accuracy: 0.9478 - val_loss: 0.0626 - val_accuracy: 0.9792\n",
            "Epoch 13/20\n",
            "370/370 [==============================] - 37s 99ms/step - loss: 0.1213 - accuracy: 0.9605 - val_loss: 0.0333 - val_accuracy: 0.9933\n",
            "Epoch 14/20\n",
            "370/370 [==============================] - 37s 99ms/step - loss: 0.1010 - accuracy: 0.9662 - val_loss: 0.0469 - val_accuracy: 0.9872\n",
            "Epoch 15/20\n",
            "370/370 [==============================] - 37s 99ms/step - loss: 0.1010 - accuracy: 0.9701 - val_loss: 0.0210 - val_accuracy: 0.9940\n",
            "Epoch 16/20\n",
            "370/370 [==============================] - 37s 99ms/step - loss: 0.0784 - accuracy: 0.9760 - val_loss: 0.0229 - val_accuracy: 0.9940\n",
            "Epoch 17/20\n",
            "370/370 [==============================] - 37s 99ms/step - loss: 0.0746 - accuracy: 0.9748 - val_loss: 0.0220 - val_accuracy: 0.9940\n",
            "Epoch 18/20\n",
            "370/370 [==============================] - 37s 99ms/step - loss: 0.0698 - accuracy: 0.9770 - val_loss: 0.0311 - val_accuracy: 0.9899\n",
            "Epoch 19/20\n",
            "370/370 [==============================] - 37s 99ms/step - loss: 0.0590 - accuracy: 0.9802 - val_loss: 0.0124 - val_accuracy: 0.9966\n",
            "Epoch 20/20\n",
            "370/370 [==============================] - 37s 99ms/step - loss: 0.0563 - accuracy: 0.9821 - val_loss: 0.0144 - val_accuracy: 0.9960\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-khCjt5mgy9",
        "outputId": "82a3a5ab-d84d-42f8-81cf-9b7f5ce3c7c3"
      },
      "source": [
        "sentiment_model.save('top15_vul_dataset_nvd_only_vulBERT_v1')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_KLbxpondY0"
      },
      "source": [
        "### **Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71CGQvvsmgvM"
      },
      "source": [
        "sentiment_model = tf.keras.models.load_model('vulBERT_v1')\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "\n",
        "def prepare_data(input_text, tokenizer):\n",
        "    token = tokenizer.encode_plus(\n",
        "        input_text,\n",
        "        max_length=256, \n",
        "        truncation=True, \n",
        "        padding='max_length', \n",
        "        add_special_tokens=True,\n",
        "        return_tensors='tf'\n",
        "    )\n",
        "    return {\n",
        "        'input_ids': tf.cast(token.input_ids, tf.float64),\n",
        "        'attention_mask': tf.cast(token.attention_mask, tf.float64)\n",
        "    }\n",
        "\n",
        "def make_prediction(model, processed_data, classes):\n",
        "    probs = model.predict(processed_data)[0]\n",
        "    return classes[np.argmax(probs)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEUtfSk9mguB",
        "outputId": "20a96f86-f018-48cd-936e-75c80320b3a2"
      },
      "source": [
        "input_text = input('Enter movie review here: ')\n",
        "processed_data = prepare_data(input_text, tokenizer)\n",
        "result = make_prediction(sentiment_model, processed_data=processed_data, classes)\n",
        "print(f\"Predicted Sentiment: {result}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter movie review here: kmMail does not sufficiently sanitize HTML and script code from the body of e-mail messages.  As a result, an attacker may send a malicious message to a user of kmMail that includes arbitrary HTML and script code.This may allow an attacker to steal cookie-based authentication credentials from users of the webmail system.  Other attacks are also possible.\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "Predicted Sentiment: CWE-79\n"
          ]
        }
      ]
    }
  ]
}